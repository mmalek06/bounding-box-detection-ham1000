{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T07:09:45.514922Z",
     "start_time": "2024-07-11T07:09:45.508713Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.datasets import CocoDetection\n",
    "\n",
    "from architectures.basic import BoundingBoxModel as BasicBoundingBoxModel\n",
    "from architectures.bigger_basic import BoundingBoxModel as BiggerBasicBoundingBoxModel\n",
    "from functions.losses import CIoULoss\n",
    "from functions.mapping import extract_bboxes\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T05:25:07.760341Z",
     "start_time": "2024-07-11T05:25:07.671019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "root = os.path.join(\"data\", \"test_images\")\n",
    "ann_file = os.path.join(\"data\", \"test_coco_annotations.json\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "dataset = CocoDetection(\n",
    "    root=root,\n",
    "    annFile=ann_file,\n",
    "    transform=transform\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=16\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ],
   "id": "8f15d136e78af2cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "cuda\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T06:53:28.680856Z",
     "start_time": "2024-07-11T06:45:26.292658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "variations = {\n",
    "    \"1\": BasicBoundingBoxModel,\n",
    "    \"2\": BiggerBasicBoundingBoxModel,\n",
    "    \"3\": BiggerBasicBoundingBoxModel\n",
    "}\n",
    "model_metrics = {\n",
    "    \"1\": [],\n",
    "    \"2\": [],\n",
    "    \"3\": []\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for filename in os.listdir(\"checkpoints\"):\n",
    "        if filename.endswith(\".pt\"):\n",
    "            parts = filename.split(\"_\")\n",
    "            model_variation = parts[1]\n",
    "            run_index = parts[5].split(\".\")[0]\n",
    "            model_path = os.path.join(\"checkpoints\", filename)\n",
    "            model = variations[model_variation]().to(device)\n",
    "            smooth_l1_loss_f = nn.SmoothL1Loss()\n",
    "            ciou_loss_f = CIoULoss()\n",
    "            \n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        \n",
    "            metrics = []\n",
    "            \n",
    "            for data in test_loader:\n",
    "                inputs, true_boxes = data\n",
    "                true_boxes = torch.stack(extract_bboxes(true_boxes)).to(device)\n",
    "                inputs = inputs.to(device)\n",
    "                pred_boxes = model(inputs)\n",
    "                l1_metric = smooth_l1_loss_f(pred_boxes, true_boxes)\n",
    "                ciou_loss = ciou_loss_f(pred_boxes, true_boxes)\n",
    "        \n",
    "                metrics.append((l1_metric, ciou_loss))\n",
    "\n",
    "            mean_l1_metric = sum(map(lambda x: x[0], metrics)) / len(metrics)\n",
    "            mean_ciou_metric = sum(map(lambda x: x[1], metrics)) / len(metrics)\n",
    "\n",
    "            model_metrics[model_variation].append((mean_l1_metric, mean_ciou_metric))"
   ],
   "id": "696d78f0cf2304ab",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T07:10:04.133980Z",
     "start_time": "2024-07-11T07:10:04.124067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_variations = {\n",
    "    \"1\": [],\n",
    "    \"2\": [],\n",
    "    \"3\": []\n",
    "}\n",
    "\n",
    "for key, tensors in model_metrics.items():\n",
    "    l1_items = list(map(lambda x: x[0].item(), tensors))\n",
    "    ciou_items = list(map(lambda x: x[1].item(), tensors))\n",
    "    min_l1 = min(l1_items)\n",
    "    min_ciou = min(ciou_items)\n",
    "    min_l1_idx = l1_items.index(min_l1)\n",
    "    min_ciou_idx = ciou_items.index(min_ciou)\n",
    "    variation_number_l1 = min_l1_idx + 1\n",
    "    variation_number_ciou = min_ciou_idx + 1\n",
    "    \n",
    "    best_variations[key].append((variation_number_l1, variation_number_ciou))\n",
    "\n",
    "with open(os.path.join(\"testing_steps\", \"best_variations.json\"), \"w\") as json_file:\n",
    "    json.dump(best_variations, json_file)"
   ],
   "id": "4e332ca3bd73228f",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d0e6018990ff3551"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-bounding_box_detection_ham10000_torch] *",
   "language": "python",
   "name": "conda-env-.conda-bounding_box_detection_ham10000_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
