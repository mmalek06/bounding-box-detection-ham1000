{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-20T07:38:23.983393Z",
     "start_time": "2024-07-20T07:38:16.271664Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.datasets import CocoDetection\n",
    "\n",
    "from architectures.basic import BoundingBoxModel as BasicBoundingBoxModel\n",
    "from architectures.bigger_basic import BoundingBoxModel as BiggerBasicBoundingBoxModel\n",
    "from functions.drawing import draw_rectangle\n",
    "from functions.losses import CIoULoss\n",
    "from functions.mapping import extract_bboxes\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T07:38:24.027868Z",
     "start_time": "2024-07-20T07:38:23.985399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "root = os.path.join(\"data\", \"test_images\")\n",
    "ann_file = os.path.join(\"data\", \"test_coco_annotations.json\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "dataset = CocoDetection(\n",
    "    root=root,\n",
    "    annFile=ann_file,\n",
    "    transform=transform\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=16\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ],
   "id": "8f15d136e78af2cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T07:38:24.033080Z",
     "start_time": "2024-07-20T07:38:24.029438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "variations = {\n",
    "    \"1\": BasicBoundingBoxModel,\n",
    "    \"2\": BiggerBasicBoundingBoxModel,\n",
    "    \"3\": BiggerBasicBoundingBoxModel\n",
    "}\n",
    "model_metrics = {\n",
    "    \"1\": [],\n",
    "    \"2\": [],\n",
    "    \"3\": []\n",
    "}"
   ],
   "id": "aa5fe21f375099d9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T07:38:24.043110Z",
     "start_time": "2024-07-20T07:38:24.034647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not os.path.exists(os.path.join(\"testing_steps\", \"best_variations.json\")):\n",
    "    with torch.no_grad():\n",
    "        for filename in os.listdir(\"checkpoints\"):\n",
    "            if filename.endswith(\".pt\"):\n",
    "                parts = filename.split(\"_\")\n",
    "                model_variation = parts[1]\n",
    "                run_index = parts[5].split(\".\")[0]\n",
    "                model_path = os.path.join(\"checkpoints\", filename)\n",
    "                model = variations[model_variation]().to(device)\n",
    "                smooth_l1_loss_f = nn.SmoothL1Loss()\n",
    "                ciou_loss_f = CIoULoss()\n",
    "                \n",
    "                model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            \n",
    "                metrics = []\n",
    "                \n",
    "                for data in test_loader:\n",
    "                    inputs, true_boxes = data\n",
    "                    true_boxes = torch.stack(extract_bboxes(true_boxes)).to(device)\n",
    "                    inputs = inputs.to(device)\n",
    "                    pred_boxes = model(inputs)\n",
    "                    l1_metric = smooth_l1_loss_f(pred_boxes, true_boxes)\n",
    "                    ciou_loss = ciou_loss_f(pred_boxes, true_boxes)\n",
    "            \n",
    "                    metrics.append((l1_metric, ciou_loss))\n",
    "    \n",
    "                mean_l1_metric = sum(map(lambda x: x[0], metrics)) / len(metrics)\n",
    "                mean_ciou_metric = sum(map(lambda x: x[1], metrics)) / len(metrics)\n",
    "    \n",
    "                model_metrics[model_variation].append((mean_l1_metric, mean_ciou_metric))"
   ],
   "id": "696d78f0cf2304ab",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T07:38:24.050923Z",
     "start_time": "2024-07-20T07:38:24.045204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not os.path.exists(os.path.join(\"testing_steps\", \"best_variations.json\")):\n",
    "    best_variations = {\n",
    "        \"1\": [],\n",
    "        \"2\": [],\n",
    "        \"3\": []\n",
    "    }\n",
    "    \n",
    "    for namespaced_key, tensors in model_metrics.items():\n",
    "        l1_items = list(map(lambda x: x[0].item(), tensors))\n",
    "        ciou_items = list(map(lambda x: x[1].item(), tensors))\n",
    "        min_l1 = min(l1_items)\n",
    "        min_ciou = min(ciou_items)\n",
    "        min_l1_idx = l1_items.index(min_l1)\n",
    "        min_ciou_idx = ciou_items.index(min_ciou)\n",
    "        variation_number_l1 = min_l1_idx + 1\n",
    "        variation_number_ciou = min_ciou_idx + 1\n",
    "        \n",
    "        best_variations[namespaced_key].append({\n",
    "            f\"{str(variation_number_l1)}_l1\": min_l1, \n",
    "            f\"{str(variation_number_ciou)}_ciou\": min_ciou\n",
    "        })\n",
    "    \n",
    "    with open(os.path.join(\"testing_steps\", \"best_variations.json\"), \"w\") as json_file:\n",
    "        json.dump(best_variations, json_file)"
   ],
   "id": "4e332ca3bd73228f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T07:38:24.057898Z",
     "start_time": "2024-07-20T07:38:24.052929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if os.path.exists(os.path.join(\"testing_steps\", \"best_variations.json\")):\n",
    "    with open(os.path.join(\"testing_steps\", \"best_variations.json\"), \"r\") as json_file:\n",
    "        best_variations = json.load(json_file) "
   ],
   "id": "d0e6018990ff3551",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T08:01:07.602808Z",
     "start_time": "2024-07-20T08:01:07.045729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "materialized_variations = []\n",
    "\n",
    "for namespaced_key, variation_numbers in best_variations.items():\n",
    "    key = namespaced_key.split(\"_\")[0]\n",
    "    model_cls = variations[key]\n",
    "\n",
    "    for filename in os.listdir(\"checkpoints\"):\n",
    "        for namespaced_variation_number in variation_numbers[0]:\n",
    "            variation_number = namespaced_variation_number.split(\"_\")[0]\n",
    "            \n",
    "            if filename.startswith(f\"checkpoint_{key}\") and filename.endswith(f\"_run_{variation_number}.pt\"):\n",
    "                model = model_cls().to(device)\n",
    "                model_path = os.path.join(\"checkpoints\", filename)\n",
    "                \n",
    "                model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "                materialized_variations.append((\n",
    "                    # model, \n",
    "                    key, \n",
    "                    variation_number, \n",
    "                    variation_numbers[0][namespaced_variation_number]\n",
    "                ))  "
   ],
   "id": "7500aa9ab0e8f947",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The best model turns out to be the bigger one. It has the lowest SmoothL1Loss function result, as well as lowest CIoU function result.",
   "id": "5a19cbe3664cbf32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T07:38:27.356718Z",
     "start_time": "2024-07-20T07:38:27.352027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(materialized_variations[2][3])\n",
    "print(materialized_variations[3][3])"
   ],
   "id": "44b11b1cb40d79a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.780552387237549\n",
      "0.22702017426490784\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T07:38:27.362324Z",
     "start_time": "2024-07-20T07:38:27.357724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_model = materialized_variations[2][0]\n",
    "out_dir = os.path.join(\"data\", \"output_phase1\")\n",
    "\n",
    "best_model.eval()\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ],
   "id": "e1ae46c7b5778e8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T07:38:46.168852Z",
     "start_time": "2024-07-20T07:38:27.363329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loader_small_batch = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=16\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (images, targets) in enumerate(test_loader_small_batch):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        img_id = dataset.ids[idx]\n",
    "        img_info = dataset.coco.loadImgs(img_id)[0]\n",
    "        img_path = img_info[\"file_name\"]\n",
    "        orig_img = PIL.Image.open(os.path.join(root, img_path))\n",
    "\n",
    "        for output in outputs:\n",
    "            coords = tuple(map(int, output[:4]))\n",
    "            output_path = os.path.join(out_dir, os.path.basename(img_path))\n",
    "            draw_rectangle(orig_img, coords, output_path)"
   ],
   "id": "9a96094b56023bb6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4fc0ed9d9463a0ad"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-bounding_box_detection_ham10000_torch] *",
   "language": "python",
   "name": "conda-env-.conda-bounding_box_detection_ham10000_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
