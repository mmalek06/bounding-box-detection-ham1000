{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-29T05:46:36.543484Z",
     "start_time": "2024-06-29T05:46:36.538183Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.datasets import CocoDetection\n",
    "\n",
    "from architectures.basic import BoundingBoxModel as BasicBoundingBoxModel\n",
    "from architectures.bigger_basic import BoundingBoxModel as BiggerBasicBoundingBoxModel\n",
    "from functions.mapping import extract_bboxes\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T05:34:51.350621Z",
     "start_time": "2024-06-29T05:34:51.332068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "root = os.path.join(\"data\", \"test_images\")\n",
    "ann_file = os.path.join(\"data\", \"test_coco_annotations.json\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "dataset = CocoDetection(\n",
    "    root=root,\n",
    "    annFile=ann_file,\n",
    "    transform=transform\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=16\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ],
   "id": "8f15d136e78af2cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "cuda\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T05:34:51.665714Z",
     "start_time": "2024-06-29T05:34:51.476966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "basic_model = BasicBoundingBoxModel().to(device)\n",
    "bigger_basic_model = BiggerBasicBoundingBoxModel().to(device)\n",
    "bigger_basic_ciou_model = BiggerBasicBoundingBoxModel().to(device)"
   ],
   "id": "5822d715eeca4878",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T05:34:51.851228Z",
     "start_time": "2024-06-29T05:34:51.666724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "basic_model.load_state_dict(torch.load(os.path.join(\"checkpoints\", \"checkpoint_1_basic.pt\"), map_location=device)[\"model_state_dict\"])\n",
    "basic_model.eval()\n",
    "bigger_basic_model.load_state_dict(torch.load(os.path.join(\"checkpoints\", \"checkpoint_2_bigger_basic.pt\"), map_location=device)[\"model_state_dict\"])\n",
    "bigger_basic_model.eval()\n",
    "bigger_basic_ciou_model.load_state_dict(torch.load(os.path.join(\"checkpoints\", \"checkpoint_3_bigger_basic_ciou.pt\"), map_location=device)[\"model_state_dict\"])\n",
    "bigger_basic_ciou_model.eval()"
   ],
   "id": "696d78f0cf2304ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundingBoxModel(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=57600, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T05:52:23.288527Z",
     "start_time": "2024-06-29T05:52:23.283388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_model(model: nn.Module) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    results = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            results.extend(outputs)\n",
    "            all_targets.extend(extract_bboxes(targets))\n",
    "            \n",
    "    return torch.stack(results).to(device), torch.stack(all_targets).to(device)"
   ],
   "id": "b64017beddbf4b75",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T05:52:48.071008Z",
     "start_time": "2024-06-29T05:52:23.427320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "basic_model_results, all_targets = test_model(basic_model)\n",
    "bigger_basic_model_results, _ = test_model(bigger_basic_model)\n",
    "bigger_basic_ciou_model_results, _ = test_model(bigger_basic_ciou_model)"
   ],
   "id": "f2e0c10b0aa21c8f",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T05:57:19.612691Z",
     "start_time": "2024-06-29T05:57:19.602661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "basic_loss = nn.SmoothL1Loss()(basic_model_results, all_targets)\n",
    "bigger_basic_loss = nn.SmoothL1Loss()(bigger_basic_model_results, all_targets)\n",
    "bigger_basic_ciou_loss = nn.SmoothL1Loss()(bigger_basic_ciou_model_results, all_targets)\n",
    "\n",
    "print(basic_loss)\n",
    "print(bigger_basic_loss)\n",
    "print(bigger_basic_ciou_loss)"
   ],
   "id": "cf375d5d5b3faeff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.0493, device='cuda:0')\n",
      "tensor(6.1762, device='cuda:0')\n",
      "tensor(9.2023, device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4e332ca3bd73228f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-bounding_box_detection_ham10000_torch] *",
   "language": "python",
   "name": "conda-env-.conda-bounding_box_detection_ham10000_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
