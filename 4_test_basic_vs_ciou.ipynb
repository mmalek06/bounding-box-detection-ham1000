{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-28T05:50:47.793682Z",
     "start_time": "2024-06-28T05:50:47.782526Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.datasets import CocoDetection\n",
    "from tqdm import tqdm\n",
    "\n",
    "from architectures.basic import BoundingBoxModel as BasicBoundingBoxModel\n",
    "from architectures.bigger_basic import BoundingBoxModel as BiggerBasicBoundingBoxModel\n",
    "from functions.loop_management import EarlyStopping\n",
    "from functions.losses import CIoULoss\n",
    "from functions.mapping import extract_bboxes\n",
    "from functions.plotting import plot_losses\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T05:50:47.925518Z",
     "start_time": "2024-06-28T05:50:47.908854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "root = os.path.join(\"data\", \"test_images\")\n",
    "ann_file = os.path.join(\"data\", \"test_coco_annotations.json\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "dataset = CocoDetection(\n",
    "    root=root,\n",
    "    annFile=ann_file,\n",
    "    transform=transform\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=16\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ],
   "id": "8f15d136e78af2cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "cuda\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T05:59:37.382444Z",
     "start_time": "2024-06-28T05:59:37.198528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "basic_model = BasicBoundingBoxModel().to(device)\n",
    "bigger_basic_model = BiggerBasicBoundingBoxModel().to(device)\n",
    "bigger_basic_ciou_model = BiggerBasicBoundingBoxModel().to(device)"
   ],
   "id": "5822d715eeca4878",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T05:59:37.618314Z",
     "start_time": "2024-06-28T05:59:37.409708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "basic_model.load_state_dict(torch.load(os.path.join(\"checkpoints\", \"checkpoint_1_basic.pt\"), map_location=device)[\"model_state_dict\"])\n",
    "basic_model.eval()\n",
    "bigger_basic_model.load_state_dict(torch.load(os.path.join(\"checkpoints\", \"checkpoint_2_bigger_basic.pt\"), map_location=device)[\"model_state_dict\"])\n",
    "bigger_basic_model.eval()\n",
    "bigger_basic_ciou_model.load_state_dict(torch.load(os.path.join(\"checkpoints\", \"checkpoint_3_bigger_basic_ciou.pt\"), map_location=device)[\"model_state_dict\"])\n",
    "bigger_basic_ciou_model.eval()"
   ],
   "id": "696d78f0cf2304ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundingBoxModel(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=57600, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T05:59:38.482211Z",
     "start_time": "2024-06-28T05:59:38.478354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_model(model: nn.Module) -> list:\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            batch_results = extract_bboxes(outputs)\n",
    "            results.extend(batch_results)\n",
    "            \n",
    "    return results"
   ],
   "id": "b64017beddbf4b75",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T05:59:51.491652Z",
     "start_time": "2024-06-28T05:59:39.206134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "basic_model_results = test_model(basic_model)\n",
    "bigger_basic_model_results = test_model(bigger_basic_model)\n",
    "bigger_basic_ciou_model_results = test_model(bigger_basic_ciou_model)"
   ],
   "id": "f2e0c10b0aa21c8f",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m basic_model_results \u001B[38;5;241m=\u001B[39m \u001B[43mtest_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbasic_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m bigger_basic_model_results \u001B[38;5;241m=\u001B[39m test_model(bigger_basic_model)\n\u001B[0;32m      3\u001B[0m bigger_basic_ciou_model_results \u001B[38;5;241m=\u001B[39m test_model(bigger_basic_ciou_model)\n",
      "Cell \u001B[1;32mIn[13], line 8\u001B[0m, in \u001B[0;36mtest_model\u001B[1;34m(model)\u001B[0m\n\u001B[0;32m      6\u001B[0m         images \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      7\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m model(images)\n\u001B[1;32m----> 8\u001B[0m         batch_results \u001B[38;5;241m=\u001B[39m \u001B[43mextract_bboxes\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m         results\u001B[38;5;241m.\u001B[39mextend(batch_results)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m results\n",
      "File \u001B[1;32mE:\\repos\\bounding-box-detection-ham1000\\functions\\mapping.py:8\u001B[0m, in \u001B[0;36mextract_bboxes\u001B[1;34m(targets)\u001B[0m\n\u001B[0;32m      5\u001B[0m bboxes \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m target \u001B[38;5;129;01min\u001B[39;00m targets:\n\u001B[1;32m----> 8\u001B[0m     xs, ys, widths, heights \u001B[38;5;241m=\u001B[39m \u001B[43mtarget\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbbox\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m idx, _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(xs):\n\u001B[0;32m     11\u001B[0m         x1, y1, width, height \u001B[38;5;241m=\u001B[39m xs[idx], ys[idx], widths[idx], heights[idx]\n",
      "\u001B[1;31mIndexError\u001B[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf375d5d5b3faeff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-bounding_box_detection_ham10000_torch] *",
   "language": "python",
   "name": "conda-env-.conda-bounding_box_detection_ham10000_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
